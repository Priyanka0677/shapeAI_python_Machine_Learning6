{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kiran.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz4hYKaZfBYM"
      },
      "source": [
        "We generally start our code by importing the libraries which we will use throughout the program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9wvyEr9e77k"
      },
      "source": [
        "import numpy as npy\n",
        "import pandas as pnd\n",
        "import sklearn"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlDIriE9fOfQ"
      },
      "source": [
        "Now we will load the data that we will be using to train our model.Here we are using boston house pricing dataset which is available in the sklearn library itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0D1BTSEfW-M"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "df = load_boston()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0zFkboPgCNx"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEuUzBq0hUVo"
      },
      "source": [
        "df.keys() # Returns all the keys of the dataset dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQZZVUB7hbp0"
      },
      "source": [
        "print(df.DESCR)  #Info about the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu3i9yJQhia4"
      },
      "source": [
        "print(df.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHfuITGTho_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57bf33c-a184-4def-ebec-028e5ef50c14"
      },
      "source": [
        "print(df.filename)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/boston_house_prices.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ9z4Vahhw5r"
      },
      "source": [
        "print(df.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnYgVdqih1-2"
      },
      "source": [
        "print(df.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VObqQa8aiLqg"
      },
      "source": [
        "We convert our dataset into the pandas dataframe, so that it is easier to analyse the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR5WfRsDiTPP"
      },
      "source": [
        "bost = pnd.DataFrame(df.data, columns=df.feature_names)\n",
        "bost.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_gWxZpommSW"
      },
      "source": [
        "Adding a new column of target values to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsqo1YPwmXmY"
      },
      "source": [
        "bost['target'] = df.target\n",
        "bost.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn7w5VSOnZby"
      },
      "source": [
        "Check if the dataset contains any null value or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCQ-OSAbnEzt"
      },
      "source": [
        "bost.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E_KJEFkoAsB"
      },
      "source": [
        "isnull return True or False for each of the cell in the dataframe, but we can't go exploring all the cells to look for True values if any, so we use sum() function to count all the cells with True value(i.e. Null cells)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUjMhel5npqM"
      },
      "source": [
        "bost.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnd2tz2XpGFC"
      },
      "source": [
        "We never train the model on all the data that we have, we always make sure to atleast have a test dataset, which is different from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n0_4mnLpAEe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = bost.drop('target', axis=1)\n",
        "Y = bost['target']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=5)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccWUrRQYp_Z8"
      },
      "source": [
        "Now let's import the linear  regression model form sklearn and trian it on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBYWZM7GpRZF"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKgoBYBcOBmv"
      },
      "source": [
        "lin_model = LinearRegression()\n",
        "lin_model.fit(X_train, Y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6eFhpS6RIWA"
      },
      "source": [
        "y_train_predict = lin_model.predict(X_train)\n",
        "rmse = (npy.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print('RMSE is{}'.format(rmse))\n",
        "print(\"\\n\")\n",
        "\n",
        "# on testing set\n",
        "y_test_predict = lin_model.predict(X_test)\n",
        "rmse = (npy.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print('RMSE is {}'.format(rmse))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}